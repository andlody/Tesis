{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1c6057b-197b-4b6c-ae15-2bc23b21ca26",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.12/site-packages (4.53.2)\n",
      "Requirement already satisfied: sentence_transformers in /opt/conda/lib/python3.12/site-packages (5.0.0)\n",
      "Requirement already satisfied: faiss-cpu in /opt/conda/lib/python3.12/site-packages (1.11.0.post1)\n",
      "Requirement already satisfied: fastapi in /opt/conda/lib/python3.12/site-packages (0.116.1)\n",
      "Requirement already satisfied: uvicorn in /opt/conda/lib/python3.12/site-packages (0.35.0)\n",
      "Requirement already satisfied: pyngrok in /opt/conda/lib/python3.12/site-packages (7.2.12)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/conda/lib/python3.12/site-packages (from transformers) (0.33.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.12/site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.12/site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.12/site-packages (from sentence_transformers) (2.6.0+cu124)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.12/site-packages (from sentence_transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.12/site-packages (from sentence_transformers) (1.15.1)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.12/site-packages (from sentence_transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/conda/lib/python3.12/site-packages (from sentence_transformers) (4.12.2)\n",
      "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in /opt/conda/lib/python3.12/site-packages (from fastapi) (0.47.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.12/site-packages (from fastapi) (2.10.6)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.12/site-packages (from uvicorn) (8.1.8)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.12/site-packages (from uvicorn) (0.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.2.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/conda/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.27.2)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /opt/conda/lib/python3.12/site-packages (from starlette<0.48.0,>=0.40.0->fastapi) (4.8.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (3.2.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (2024.12.14)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.12/site-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install transformers sentence_transformers faiss-cpu fastapi uvicorn pyngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0af37c2a-70b2-4350-922f-93138875bdc0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5601d798731043f1b23cd67f37150978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(modelo_id)\n\u001b[1;32m     11\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodelos/Phi-4-mini-instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m modelo \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodelo_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m modelo\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodelos/Phi-4-mini-instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:600\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mconfig_class \u001b[38;5;241m==\u001b[39m config\u001b[38;5;241m.\u001b[39msub_configs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    599\u001b[0m         config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget_text_config()\n\u001b[0;32m--> 600\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    606\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/transformers/modeling_utils.py:311\u001b[0m, in \u001b[0;36mrestore_default_torch_dtype.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    313\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/transformers/modeling_utils.py:4839\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4830\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   4832\u001b[0m     (\n\u001b[1;32m   4833\u001b[0m         model,\n\u001b[1;32m   4834\u001b[0m         missing_keys,\n\u001b[1;32m   4835\u001b[0m         unexpected_keys,\n\u001b[1;32m   4836\u001b[0m         mismatched_keys,\n\u001b[1;32m   4837\u001b[0m         offload_index,\n\u001b[1;32m   4838\u001b[0m         error_msgs,\n\u001b[0;32m-> 4839\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4842\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4845\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4846\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4848\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4849\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4853\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4855\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4857\u001b[0m \u001b[38;5;66;03m# record tp degree the model sharded to\u001b[39;00m\n\u001b[1;32m   4858\u001b[0m model\u001b[38;5;241m.\u001b[39m_tp_size \u001b[38;5;241m=\u001b[39m tp_size\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/transformers/modeling_utils.py:5302\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001b[0m\n\u001b[1;32m   5299\u001b[0m         args_list \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mtqdm(args_list, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading checkpoint shards\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5301\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m args_list:\n\u001b[0;32m-> 5302\u001b[0m         _error_msgs, disk_offload_index, cpu_offload_index \u001b[38;5;241m=\u001b[39m \u001b[43mload_shard_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5303\u001b[0m         error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m _error_msgs\n\u001b[1;32m   5305\u001b[0m \u001b[38;5;66;03m# Adjust offloaded weights name and save if needed\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/transformers/modeling_utils.py:933\u001b[0m, in \u001b[0;36mload_shard_file\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    931\u001b[0m \u001b[38;5;66;03m# Skip it with fsdp on ranks other than 0\u001b[39;00m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_fsdp_enabled() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_local_dist_rank_0() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_quantized):\n\u001b[0;32m--> 933\u001b[0m     disk_offload_index, cpu_offload_index \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshard_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreverse_key_renaming_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisk_offload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcpu_offload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcpu_offload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcpu_offload_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcpu_offload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_offloaded_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m error_msgs, disk_offload_index, cpu_offload_index\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/transformers/modeling_utils.py:810\u001b[0m, in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, shard_file, expected_keys, reverse_renaming_mapping, device_map, disk_offload_folder, disk_offload_index, cpu_offload_folder, cpu_offload_index, hf_quantizer, is_safetensors, keep_in_fp32_regex, unexpected_keys, device_mesh)\u001b[0m\n\u001b[1;32m    808\u001b[0m param \u001b[38;5;241m=\u001b[39m param[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n\u001b[1;32m    809\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m casting_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 810\u001b[0m     param \u001b[38;5;241m=\u001b[39m \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasting_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m to_contiguous:\n\u001b[1;32m    812\u001b[0m     param \u001b[38;5;241m=\u001b[39m param\u001b[38;5;241m.\u001b[39mcontiguous()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Descargar y guardar el modelo de embeddings localmente\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embedder.save(\"modelos/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Descargar y guardar el tokenizer y modelo de lenguaje\n",
    "modelo_id = \"microsoft/Phi-4-mini-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelo_id)\n",
    "tokenizer.save_pretrained(\"modelos/Phi-4-mini-instruct\")\n",
    "\n",
    "modelo = AutoModelForCausalLM.from_pretrained(modelo_id)\n",
    "modelo.save_pretrained(\"modelos/Phi-4-mini-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c251309d-18f3-4290-8650-650c883cff77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola\n"
     ]
    }
   ],
   "source": [
    "## Correr desde aqui....!!\n",
    "print('Hola')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dca844e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1bd460dee4546988fc9ba0a466907a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cargar tokenizer y modelo de lenguaje localmente\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "#torch.set_num_threads(8)\n",
    "\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"modelos/Phi-4-mini-instruct\")\n",
    "#modelo = AutoModelForCausalLM.from_pretrained(\"modelos/Phi-4-mini-instruct\", torch_dtype=torch.bfloat16).to(\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-4-mini-instruct\")\n",
    "modelo = AutoModelForCausalLM.from_pretrained(\"microsoft/Phi-4-mini-instruct\", torch_dtype=torch.bfloat16).to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49f9f44c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.get_num_threads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36ff703c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Cargar modelo localmente\n",
    "embedder = SentenceTransformer(\"modelos/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d1b0c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "embeddings = np.load(\"embeddings/CHUNK_PRODUCTO.npy\")\n",
    "#embeddings = np.concatenate((embeddings,np.load(\"embeddings/CHUNK_FICHA.npy\")))\n",
    "#embeddings = np.concatenate((embeddings,np.load(\"embeddings/CHUNK_DESCRIPCION.npy\")))\n",
    "#embeddings = np.concatenate((embeddings,np.load(\"embeddings/CHUNK_CARACTERISTICAS.npy\")))\n",
    "#embeddings = np.concatenate((embeddings,np.load(\"embeddings/CHUNK_OBSERVACIONES.npy\")))\n",
    "#embeddings = np.concatenate((embeddings,np.load(\"embeddings/CHUNK_RECOMENDACIONES.npy\")))\n",
    "\n",
    "# Crear índice FAISS\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "index.add(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8af6fca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"procesos/productos_corpus.csv\",delimiter=\",\")\n",
    "df['CHUNK_DESCRIPCION'] = df['CHUNK_DESCRIPCION'].fillna('')\n",
    "df['CHUNK_CARACTERISTICAS'] = df['CHUNK_CARACTERISTICAS'].fillna('')\n",
    "df['CHUNK_OBSERVACIONES'] = df['CHUNK_OBSERVACIONES'].fillna('')\n",
    "df['CHUNK_RECOMENDACIONES'] = df['CHUNK_RECOMENDACIONES'].fillna('')\n",
    "tamanio = len(df)\n",
    "\n",
    "def getChunk(n):\n",
    "    cociente, resto = divmod(n, tamanio)\n",
    "    chunk = ['CHUNK_PRODUCTO', 'CHUNK_FICHA', 'CHUNK_DESCRIPCION', 'CHUNK_CARACTERISTICAS', 'CHUNK_OBSERVACIONES', 'CHUNK_RECOMENDACIONES']\n",
    "    return str(df.iloc[resto][chunk[cociente]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f26ec39b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ovalin circular para sobreponer vidriotransparente de la marca orange del area de baños para los sanitarios de la linea ovalines de procedencia importado al precio de 79.9 soles'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getChunk(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d1e7245-3d98-4e37-8b29-3f9230b6ecd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelScore(pregunta):\n",
    "    contexto = \"ovalin circular para sobreponer vidrio transparente de la marca orange del area de baños para los sanitarios de la linea ovalines de procedencia importado al precio de 79.9 soles\"\n",
    "    prompt = f\"\"\"\n",
    "    CONTEXTO:\n",
    "    {contexto}\n",
    "    PREGUNTA: {pregunta}\n",
    "    RESPUESTA:\"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(modelo.device)\n",
    "    outputs = modelo.generate(**inputs, min_new_tokens=10, max_new_tokens=25, do_sample=True, top_p=0.5, temperature=0.1)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8677cf94-b0d4-4b08-a2a2-103185f1a618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    CONTEXTO:\\n    ovalin circular para sobreponer vidrio transparente de la marca orange del area de baños para los sanitarios de la linea ovalines de procedencia importado al precio de 79.9 soles\\n    PREGUNTA: Cual es la procedencia del ovalin?\\n    RESPUESTA: La procedencia del ovalin es de procedencia importado.\\n    CONTEXTO:\\n    ovalin circular para sobreponer'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelScore('Cual es la procedencia del ovalin?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54b80267-c024-47a0-9997-d29b849ced45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    CONTEXTO:\\n    ovalin circular para sobreponer vidrio transparente de la marca orange del area de baños para los sanitarios de la linea ovalines de procedencia importado al precio de 79.9 soles\\n    PREGUNTA: Cual es el precio de ovalin?\\n    RESPUESTA: El precio de ovalin es de 79.9 soles.\\n    CONTEXTO:\\n    ovalin circular para sobreponer'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelScore('Cual es el precio de ovalin?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce6ab52b-5d32-4524-8777-5e84f3eb552f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    CONTEXTO:\\n    ovalin circular para sobreponer vidrio transparente de la marca orange del area de baños para los sanitarios de la linea ovalines de procedencia importado al precio de 79.9 soles\\n    PREGUNTA: el ovalin es circular o cuadrado?\\n    RESPUESTA: el ovalin es circular\\n    CONTEXTO:\\n    ovalin circular para sobreponer vidrio transparente de la marca orange del'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelScore('el ovalin es circular o cuadrado?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7692871e-5cbe-4a68-bf57-296ad749dc0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    CONTEXTO:\\n    ovalin circular para sobreponer vidrio transparente de la marca orange del area de baños para los sanitarios de la linea ovalines de procedencia importado al precio de 79.9 soles\\n    PREGUNTA: de que marca es el ovalin?\\n    RESPUESTA: el ovalin es de la marca orange\\n    CONTEXTO:\\n    ovalin circular para sobreponer vidrio transparente de la'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelScore('de que marca es el ovalin?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c255c403-cf16-4c48-a369-830bd9a30a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    CONTEXTO:\\n    ovalin circular para sobreponer vidrio transparente de la marca orange del area de baños para los sanitarios de la linea ovalines de procedencia importado al precio de 79.9 soles\\n    PREGUNTA: de que area es el ovalin?\\n    RESPUESTA: el ovalin es un tipo de vidrio de la marca orange, utilizado para cubrir los sanitarios en la línea ovalines de'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelScore('de que area es el ovalin?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ede2b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelx(pregunta, k=3, temperatura=0.2):\n",
    "    #print('1.- encode')\n",
    "    # Embed la pregunta\n",
    "    pregunta_emb = embedder.encode([pregunta], convert_to_numpy=True)\n",
    "\n",
    "    # Buscar los k textos más cercanos\n",
    "    distancias, indices = index.search(pregunta_emb, k)\n",
    "    contexto = \"\\n\".join([getChunk(i) for i in indices[0]])\n",
    "\n",
    "    #print(contexto)\n",
    "    #print(distancias)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    CONTEXTO:\n",
    "    {contexto}\n",
    "    PREGUNTA: {pregunta}\n",
    "    RESPUESTA:\"\"\"\n",
    "\n",
    "   \n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(modelo.device)\n",
    "    #print('3.- generate')\n",
    "    outputs = modelo.generate(**inputs, min_new_tokens=10, max_new_tokens=250, do_sample=True, top_p=0.5, temperature=temperatura)\n",
    "\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adb95a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def respuestaModel(pregunta,k=3,temperatura=0.2):\n",
    "    tok = modelx(pregunta, k,temperatura)\n",
    "    # Buscar la primera respuesta\n",
    "    #match = re.search(r\"RESPUESTA:\\s*(.+?)(?=\\n\\s*PREGUNTA:|\\Z)\", tok, re.DOTALL | re.IGNORECASE)\n",
    "    #return match.group(1).strip()\n",
    "\n",
    "    respuestas = re.findall(r\"RESPUESTA:\\s*(.+?)(?=\\n\\s*PREGUNTA:|\\n\\s*CONTEXTO:|\\Z)\", tok, re.DOTALL | re.IGNORECASE)\n",
    "\n",
    "    # Filtramos respuestas que al menos terminan en un número (como \"179.9 soles\")\n",
    "    #respuestas_validas = [r.strip() for r in respuestas if re.search(r\"\\d+(\\.\\d+)?\\s+soles\", r)]\n",
    "    return respuestas[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9beb00a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    CONTEXTO:\n",
      "    ovalin para sobreponer luna blanco de la marca trebol del area de baños para los sanitarios de la linea ovalines de procedencia nacional al precio de 187.0 soles\n",
      "ovalin para sobreponer divani blanco de la marca trebol del area de baños para los sanitarios de la linea ovalines de procedencia nacional al precio de 179.9 soles\n",
      "ovalin circular mimbell blanco de la marca trebol del area de baños para los sanitarios de la linea ovalines de procedencia nacional al precio de 187.0 soles\n",
      "    PREGUNTA: quiero un ovalin para mi baño, cuales tienen?\n",
      "    RESPUESTA: ovalin para sobreponer divani blanco de la marca trebol del area de baños para los sanitarios de la linea ovalines de procedencia nacional al precio de 179.9 soles\n",
      "    CONTEXTO:\n",
      "    ovalin para sobreponer divani blanco de la marca trebol del area de baños para los sanitarios de la linea ovalines de procedencia nacional al precio de 179.9 soles\n",
      "    PREGUNTA: quiero un ovalin para mi baño, cuales tienen?\n",
      "    RESPUESTA: ovalin para sobreponer divani blanco de la marca trebol del area de baños para los sanitarios de la linea ovalines de procedencia nacional al precio de 179.9 soles\n",
      "    CONTEXTO:\n",
      "    ovalin para sobreponer divani blanco de la marca trebol del area de baños para los sanitarios de la linea ovalines de procedencia nacional al precio de 179.9 soles\n",
      "    PREGUNTA: quiero un ovalin para mi baño, cuales tienen?\n",
      "    RESPUESTA: ovalin para sobreponer divani blanco de la marca trebol del area de baños para los sanitarios de la linea ovalines de procedencia nacional al precio de 179.9 soles\n"
     ]
    }
   ],
   "source": [
    "print(modelx('quiero un ovalin para mi baño, cuales tienen?',3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1593e648",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el ovalin para sobreponer divani blanco de la marca trebol del area de baños para los sanitarios de la linea ovalines de procedencia nacional al precio de 179.9 soles\n"
     ]
    }
   ],
   "source": [
    "print(respuestaModel('quiero un ovalin para mi baño, cuales tienen?',3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab4fa7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La marca Smacks es una de las más reconocidas en la industria de muebles, especialmente en la categoría de camas. Ofrecen una amplia variedad de camas con diferentes estilos, tamaños y acabados, lo que permite encontrar la opción perfecta para tus necesidades y preferencias. Si buscas una cama, te recomiendo visitar su sitio web o visitar una de sus tiendas físicas para explorar su catálogo y encontrar la cama que mejor se adapte a tu espacio y estilo de vida. Recuerda considerar factores como el tamaño, el material, el diseño y el precio al tomar tu decisión.\n"
     ]
    }
   ],
   "source": [
    "print(respuestaModel('quiero una cama, cual me recomiendas?',3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7bd3606-6e2c-4bc0-9d3c-f9403967fa6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La marca del ovalin divani es Trebol.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "messagesX = [\n",
    "    {\"role\": \"system\", \"content\": \"Hola, en que puedo ayudarte?\"},\n",
    "    {\"role\": \"user\", \"content\": \"Soy Andree, quiero saber cuantos dias tiene un año\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"un año tiene 365 dias\"},\n",
    "    {\"role\": \"user\", \"content\": \"y cuantos viernes? ademas recuerdas mi nombre?\"},\n",
    "]\n",
    "\n",
    "messagesY = [\n",
    "    {\"role\": \"system\", \"content\": \"Hola, en que puedo ayudarte?\"},\n",
    "    {\"role\": \"user\", \"content\": \"contexto: el ovalin para sobreponer divani blanco de la marca trebol del area de baños para los sanitarios de la linea ovalines de procedencia nacional al precio de 179.9 soles\"},\n",
    "    #{\"role\": \"assistant\", \"content\": \"un año tiene 365 dias\"},\n",
    "    {\"role\": \"user\", \"content\": \"cuanto cuesta el ovalin? divani\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"El precio del Ovalin mencionado es de 179.9 soles. Sin embargo, es importante tener en cuenta que el Ovalin es un producto de decoración, específicamente un tipo de alfombra, y no un divani. Si estás buscando un divani, es posible que necesites buscar opciones separadas, ya que los precios y las características pueden variar significativamente.\"},\n",
    "    {\"role\": \"user\", \"content\": \"cual es la marca de ese ovalin?\"}\n",
    "]\n",
    "\n",
    "messages = [ \n",
    "    {\"role\": \"system\", \"content\": \"contexto: el ovalin para sobreponer divani blanco de la marca trebol del area de baños para los sanitarios de la linea ovalines de procedencia nacional al precio de 179.9 soles\"},\n",
    "    {\"role\": \"user\", \"content\": \"cuanto cuesta el ovalin divani?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"El ovalin divani cuesta 179.9 soles. Este producto es un divani blanco de la marca Trebol, diseñado para el área de baños de los sanitarios, y su procedencia es nacional.\"},\n",
    "    {\"role\": \"user\", \"content\": \"cual es la marca?\"}\n",
    "]\n",
    " \n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=modelo,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    " \n",
    "generation_args = {\n",
    "    \"max_new_tokens\": 500,\n",
    "    \"return_full_text\": False,\n",
    "    \"temperature\": 0.0,\n",
    "    \"do_sample\": False,\n",
    "}\n",
    " \n",
    "output = pipe(messages, **generation_args)\n",
    "print(output[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28c07a61-bde5-456c-8a84-bee6fe3e7093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def promartBoot(texto,mensajes,k):\n",
    "    # --------\n",
    "    pregunta_emb = embedder.encode([texto], convert_to_numpy=True)\n",
    "    # Buscar los k textos más cercanos\n",
    "    distancias, indices = index.search(pregunta_emb, k)\n",
    "    contexto = \"\\n\".join([getChunk(i) for i in indices[0]])\n",
    "    mensajes.append({\"role\": \"system\",\"content\":\"CONTEXTO: \"+contexto})\n",
    "    #print(contexto)\n",
    "    print('----------------')\n",
    "    # --------\n",
    "    \n",
    "    mensajes.append({\"role\": \"user\",\"content\":texto})\n",
    "    \n",
    "    pipe = pipeline(\"text-generation\", model=modelo, tokenizer=tokenizer)\n",
    "     \n",
    "    generation_args = {\n",
    "        \"max_new_tokens\": 500,\n",
    "        \"return_full_text\": False,\n",
    "        \"temperature\": 0.0,\n",
    "        \"do_sample\": False,\n",
    "    }\n",
    "     \n",
    "    output = pipe(mensajes, **generation_args)\n",
    "    return output[0]['generated_text']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c20c1c4-001b-46bf-b72f-b33cd8955dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Parece que estás buscando un ovalin circular mimbell. Si estás interesado en comprar uno, aquí tienes una sugerencia basada en tus preferencias:\\n\\n**Ovalin circular mimbell de la marca Italgrif del área de baños para los sanitarios de la línea ovalines de procedencia nacional al precio de 155.0 soles.**\\n\\nSi necesitas más opciones o tienes otras especificaciones, no dudes en informarme. ¡Estoy aquí para ayudarte!'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promartBoot('necesito un ovalin circular mimbell',[],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f99026bf-6e25-4bcc-bfbe-a6e80b19bf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from pydantic import BaseModel\n",
    "import nest_asyncio\n",
    "import uvicorn\n",
    "from pyngrok import ngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02af3fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 API disponible en: NgrokTunnel: \"https://f291cc1df7e3.ngrok-free.app\" -> \"http://localhost:8000\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [46]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "nest_asyncio.apply()\n",
    "app = FastAPI()\n",
    "\n",
    "app.add_middleware(\n",
    "        CORSMiddleware,\n",
    "        allow_origins=[\"*\"],  # Your defined list of allowed origins\n",
    "        allow_credentials=True,  # Allow cookies and authorization headers\n",
    "        allow_methods=[\"*\"],  # Allow all HTTP methods (GET, POST, PUT, etc.)\n",
    "        allow_headers=[\"*\"],  # Allow all headers\n",
    "    )\n",
    "\n",
    "class Body(BaseModel):\n",
    "    pregunta: str\n",
    "    k: int\n",
    "    history: list\n",
    "\n",
    "@app.post(\"/clasificar\")\n",
    "def clasificar(body: Body):\n",
    "    texto = body.pregunta\n",
    "    k = body.k\n",
    "    history = body.history\n",
    "    return {\"respuesta\": promartBoot(texto,history,k)}\n",
    "\n",
    "# Inicia el tunel ngrok\n",
    "ngrok.set_auth_token(\"1o4ItumAvMRlaYTG9dxyHKNInZq_48f9Txagc76SkaUUpoZB4\")\n",
    "public_url = ngrok.connect(8000)\n",
    "print(f\"🔗 API disponible en: {public_url}\")\n",
    "\n",
    "uvicorn.run(app, port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26648066-4d5b-4acf-bb88-5cee871ccb11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holax\n"
     ]
    }
   ],
   "source": [
    "print('holax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95bac51-f189-4d2b-84a4-aecfbc7ec13a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
