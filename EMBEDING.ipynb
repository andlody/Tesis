{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8aabbbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.11.0.post1-cp310-cp310-macosx_14_0_arm64.whl.metadata (5.0 kB)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-5.0.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.53.2-py3-none-any.whl.metadata (40 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from faiss-cpu) (2.1.3)\n",
      "Requirement already satisfied: packaging in /Users/andlody/Library/Python/3.10/lib/python/site-packages (from faiss-cpu) (25.0)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sentence-transformers) (2.7.0)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sentence-transformers) (1.6.0)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sentence-transformers) (0.33.4)\n",
      "Requirement already satisfied: Pillow in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /Users/andlody/Library/Python/3.10/lib/python/site-packages (from sentence-transformers) (4.14.1)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.9.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->transformers) (2025.4.26)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Downloading faiss_cpu-1.11.0.post1-cp310-cp310-macosx_14_0_arm64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached sentence_transformers-5.0.0-py3-none-any.whl (470 kB)\n",
      "Using cached transformers-4.53.2-py3-none-any.whl (10.8 MB)\n",
      "Installing collected packages: faiss-cpu, transformers, sentence-transformers\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [sentence-transformers]ence-transformers]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autotrain-advanced 0.8.36 requires accelerate==1.2.1, but you have accelerate 1.9.0 which is incompatible.\n",
      "autotrain-advanced 0.8.36 requires huggingface-hub==0.27.0, but you have huggingface-hub 0.33.4 which is incompatible.\n",
      "autotrain-advanced 0.8.36 requires packaging==24.2, but you have packaging 25.0 which is incompatible.\n",
      "autotrain-advanced 0.8.36 requires Pillow==11.0.0, but you have pillow 11.3.0 which is incompatible.\n",
      "autotrain-advanced 0.8.36 requires sentence-transformers==3.3.1, but you have sentence-transformers 5.0.0 which is incompatible.\n",
      "autotrain-advanced 0.8.36 requires tensorboard==2.18.0, but you have tensorboard 2.19.0 which is incompatible.\n",
      "autotrain-advanced 0.8.36 requires transformers==4.48.0, but you have transformers 4.53.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed faiss-cpu-1.11.0.post1 sentence-transformers-5.0.0 transformers-4.53.2\n"
     ]
    }
   ],
   "source": [
    "!pip3 install faiss-cpu sentence-transformers transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4a992a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Descargar y guardar el modelo de embeddings localmente\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embedder.save(\"modelos/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Descargar y guardar el tokenizer y modelo de lenguaje\n",
    "modelo_id = \"microsoft/Phi-4-mini-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelo_id)\n",
    "tokenizer.save_pretrained(\"modelos/Phi-4-mini-instruct\")\n",
    "\n",
    "modelo = AutoModelForCausalLM.from_pretrained(modelo_id)\n",
    "modelo.save_pretrained(\"modelos/Phi-4-mini-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb8a2e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46490"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"procesos/productos_corpus.csv\",delimiter=\",\")\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1bd7a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Cargar modelo localmente\n",
    "embedder = SentenceTransformer(\"modelos/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a4aab3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c1c20a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CHUNK_DESCRIPCION'] = df['CHUNK_DESCRIPCION'].fillna('')\n",
    "df['CHUNK_CARACTERISTICAS'] = df['CHUNK_CARACTERISTICAS'].fillna('')\n",
    "df['CHUNK_OBSERVACIONES'] = df['CHUNK_OBSERVACIONES'].fillna('')\n",
    "df['CHUNK_RECOMENDACIONES'] = df['CHUNK_RECOMENDACIONES'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9b8fbd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir textos a embeddings\n",
    "corpus_embeddings = embedder.encode(df['CHUNK_PRODUCTO'].tolist(), convert_to_numpy=True)\n",
    "np.save(\"embeddings/CHUNK_PRODUCTO.npy\", corpus_embeddings)\n",
    "\n",
    "corpus_embeddings = embedder.encode(df['CHUNK_FICHA'].tolist(), convert_to_numpy=True)\n",
    "np.save(\"embeddings/CHUNK_FICHA.npy\", corpus_embeddings)\n",
    "\n",
    "corpus_embeddings = embedder.encode(df['CHUNK_DESCRIPCION'].tolist(), convert_to_numpy=True)\n",
    "np.save(\"embeddings/CHUNK_DESCRIPCION.npy\", corpus_embeddings)\n",
    "\n",
    "corpus_embeddings = embedder.encode(df['CHUNK_CARACTERISTICAS'].tolist(), convert_to_numpy=True)\n",
    "np.save(\"embeddings/CHUNK_CARACTERISTICAS.npy\", corpus_embeddings)\n",
    "\n",
    "corpus_embeddings = embedder.encode(df['CHUNK_OBSERVACIONES'].tolist(), convert_to_numpy=True)\n",
    "np.save(\"embeddings/CHUNK_OBSERVACIONES.npy\", corpus_embeddings)\n",
    "\n",
    "corpus_embeddings = embedder.encode(df['CHUNK_RECOMENDACIONES'].tolist(), convert_to_numpy=True)\n",
    "np.save(\"embeddings/CHUNK_RECOMENDACIONES.npy\", corpus_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "688b224d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46490"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = np.load(\"embeddings/CHUNK_PRODUCTO.npy\")\n",
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3a958a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278940"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = np.load(\"embeddings/CHUNK_PRODUCTO.npy\")\n",
    "embeddings = np.concatenate((embeddings,np.load(\"embeddings/CHUNK_FICHA.npy\")))\n",
    "embeddings = np.concatenate((embeddings,np.load(\"embeddings/CHUNK_DESCRIPCION.npy\")))\n",
    "embeddings = np.concatenate((embeddings,np.load(\"embeddings/CHUNK_CARACTERISTICAS.npy\")))\n",
    "embeddings = np.concatenate((embeddings,np.load(\"embeddings/CHUNK_OBSERVACIONES.npy\")))\n",
    "embeddings = np.concatenate((embeddings,np.load(\"embeddings/CHUNK_RECOMENDACIONES.npy\")))\n",
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "83db822f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear índice FAISS\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "index.add(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d461a271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5738011  0.5738011  0.5855775  0.61449397 0.6273186  0.6365832\n",
      "  0.639634   0.639634   0.639634   0.639634  ]]\n",
      "[[256196 256215 116950 105933 193892 112340 106684 106685 106686 106687]]\n"
     ]
    }
   ],
   "source": [
    "def responder_pregunta_rag(pregunta, k=10):\n",
    "    # Embed la pregunta\n",
    "    pregunta_emb = embedder.encode([pregunta], convert_to_numpy=True)\n",
    "\n",
    "    # Buscar los k textos más cercanos\n",
    "    distancias, indices = index.search(pregunta_emb, k)\n",
    "    print(distancias)\n",
    "    print(indices)\n",
    "\n",
    "responder_pregunta_rag('necesito una refrigeradora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fc945df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.47783175 0.48447216 0.48447216 0.48447216 0.48447216 0.48447216\n",
      "  0.48447216 0.48447216 0.48447216 0.5248814 ]]\n",
      "[[176543 224699 224700 224701 224702 224703 224704 227696 227697 227731]]\n"
     ]
    }
   ],
   "source": [
    "responder_pregunta_rag('necesito una refrigeradora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "28fa268e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "37073\n"
     ]
    }
   ],
   "source": [
    "#resto = 256196 % 46490\n",
    "cociente, resto = divmod(176543, 46490)\n",
    "print(cociente)\n",
    "print(resto)\n",
    "# ['CHUNK_PRODUCTO', 'CHUNK_FICHA', 'CHUNK_DESCRIPCION', 'CHUNK_CARACTERISTICAS', 'CHUNK_OBSERVACIONES', 'CHUNK_RECOMENDACIONES']\n",
    "# 46490 productos del 0 al 46489"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "07d96339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SKU                                                                 156424\n",
       "DESCRIPCION                        OSTER FRIGOBAR 122LTS OS-PMB129BB NEGRO\n",
       "DES_DIV                                                       HOGAR Y DECO\n",
       "DES_AREA                                                     ELECTRO HOGAR\n",
       "DES_DPTO                                                      LINEA BLANCA\n",
       "DES_LIN                                                     REFRIGERADORAS\n",
       "DES_MARCA                                                            OSTER\n",
       "DES_PROCE                                                         NACIONAL\n",
       "URL                                                                    NaN\n",
       "PRECIO                                                               999.0\n",
       "CHUNK_PRODUCTO           oster frigobar 122lts os-pmb129bb negro de la ...\n",
       "CHUNK_FICHA              acabado liso, altura del producto 84.00 cm, an...\n",
       "CHUNK_DESCRIPCION        Compartimiento refrigerado. Control de tempera...\n",
       "CHUNK_CARACTERISTICAS    Compartimiento refrigerado. Patas ajustables. ...\n",
       "CHUNK_OBSERVACIONES      Ideal para espacios pequeños del hogar u ofici...\n",
       "CHUNK_RECOMENDACIONES            Colocar en superficies totalmente planas.\n",
       "Name: 37073, dtype: object"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[37073]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
